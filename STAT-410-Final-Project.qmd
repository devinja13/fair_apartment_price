---
title: "Determining a Fair Apartment Price"
subtitle: "Stat 410 Final Project"
author: "Jack Dzialo, Devin Abraham, Tom Vincent"
format: pdf
---

```{r setup, include=FALSE}
library(ggplot2)
library(data.table)
library(dplyr)
library(stringr)
library(car)
```

```{r, echo=FALSE, include=FALSE}
data <- read.csv2("apartments.csv")
cleaned <- data %>%
              filter(currency == "USD", price_type == "Monthly", nchar(state) == 2, bathrooms != "null", !bedrooms %in% c("null", "USD", "") ) %>%
              mutate(pets_allowed = ifelse(pets_allowed %in% c("Cats", "Dogs", "Cats, Dogs", "Cats, Dogs, None"), 1, 0)) %>%
              mutate(has_photo = ifelse(has_photo %in% c("Thumbnail", "Yes"), 1, 0)) %>%
              mutate(fee = ifelse(fee == "Yes", 1, 0))
cities <- read.csv("uscities.csv")
cleaned <- cleaned %>%
  mutate(city = tolower(cityname), state = tolower(state))
cities <- cities %>%
  mutate(city = tolower(city), state = tolower(state_id))
cleaned <- cleaned %>%
  mutate(city = trimws(city), state = trimws(state))
cities <- cities %>%
  mutate(city = trimws(city), state = trimws(state))
data <- cleaned %>%
  left_join(cities %>% select(city, state, population, density),
            by = c("city", "state"))
#can do either median or mean.
pop_mean <- (mean(cities$population, na.rm=TRUE))
density_med <- mean(cities$density, na.rm=TRUE)
cleaned <- mutate(data, population = ifelse(is.na(population), pop_mean, population), density = ifelse(is.na(density), density_med, density))
Y <- cleaned$price
cleaned$bathrooms <- as.numeric(cleaned$bathrooms)
cleaned$bedrooms <- as.numeric(cleaned$bedrooms)
cleaned$price <- as.numeric(cleaned$price)
cleaned$density <- as.numeric(cleaned$density)
cleaned$population <- as.numeric(cleaned$population)
cleaned$square_feet <- as.numeric(cleaned$square_feet)
```

## Purpose

When coming up with ideas for our final project, we wanted to work on something that related to a real problem that we had in our lives. Our whole group is looking for housing next year, both near Rice and out of Houston. Two of us are looking for larger houses to share with roommates, while one is looking for a one 1-2 bedroom apartment in a different city. Since we are all facing the same problem, but are looking at many different housing factors we wanted to come up with a model to ensure we are getting a fair price for the given housing option, or even find below-market opportunities allowing us to get a great deal. Since there are so many houses on the market all with different qualities, it is difficult to determine a fair price. 

Therefore, for our final project, we aim to address the problem of accurately predicting apartment prices based on a variety of influencing factors. Our primary goal is to develop a reliable regression model that can assess the fairness of rental prices, providing a valuable tool for prospective renters to make informed decisions. The effects of variables such as location, size, amenities, and neighborhood characteristics on rental costs are of particular interest, as understanding these can aid in identifying key drivers of price variations. By achieving these objectives, we hope to contribute to a more transparent rental market.


## Definitions

1.  $AIC$: Measures trade off between model fit and complexity with a penalty for more complexity
2.  $AIC_c$: Corrected version of AIC with a larger penalty for regressors
3.  $BIC$: Penalizes model complexity heavily and favors simple model with large sample sizes
4.  $PRESS$: Predicted Residual Error Sum of Squares; predicts how accurate a model is at predicting data it hasn't seen before

## Data Collection
We got our data from the UC Irvine Machine Learning repository titled Apartment for Rent. In addition, we supplemented this dataset with a US cities dataset from Simple Maps so we could include the population and density of the city the apartment is located in. The Apartment for Rent dataset included 22 variables and 52,746 oberservations. The 22 variables included id, category, title, body, amenities, bathrooms, bedrooms, currency, fee, has_photo, pets_allowed, price, price_display, price_type, square_feet, address, cityname, state, latitude, longitude, source, time. After exploring the data, we found columns with just text such as Title, Body, and Address which we were not able to turn into quantitative data or factors so we decided to not include it in the model. In addition, we did not include the following columns since they were not directly related to the housing. We removed id, category, currency, price_type, state, latitude, longitude, and time. To include the population and density of the city, were able to merge the datasets including the population and density for the listed city in each row. There were a range of responses for pets_allowed, has_fee, and has_photo but we were able to convert them into binary indicator variables 1 for yes, 0 for no. 


```{r, fig.width=8, fig.height=6, echo=FALSE}

data$price <- as.numeric(data$price)
hist(data$price,
     freq = FALSE,
     breaks = "scott",
     main = "Histogram of Price",
     xlab = "Price (dollars)",
     col = "lightblue",
     xlim = c(0, 10000))
```

##  Data Synopsis for All Variables
```{r data, echo=FALSE}
table <- data.frame(
  Statistic = c("Mean Price", "Max Price", "Min Price", "Median Price"),
  Value = c(round(mean(cleaned$price, na.rm = TRUE)),
            round(max(cleaned$price, na.rm = TRUE)),
            round(min(cleaned$price, na.rm = TRUE)),
            round(median(cleaned$price, na.rm = TRUE))
))
knitr::kable(table)

data$square_feet <- as.numeric(data$square_feet)

table <- data.frame(
  Statistic = c("Mean Square Feet", "Max Square Feet", "Min Square Feet", "Median Square Feet"),
  Value = c(round(mean(cleaned$square_feet, na.rm = TRUE)),
            round(max(cleaned$square_feet, na.rm = TRUE)),
            round(min(cleaned$square_feet, na.rm = TRUE)),
            round(median(cleaned$square_feet, na.rm = TRUE))
))
knitr::kable(table)

cleaned$bedrooms <- as.numeric(cleaned$bedrooms)

table <- data.frame(
  Statistic = c("Mean Bedrooms", "Max Bedrooms", "Min Bedrooms", "Median Bedrooms"),
  Value = c(round(mean(cleaned$bedrooms, na.rm=TRUE)),
            max(cleaned$bedrooms, na.rm = TRUE),
            min(cleaned$bedrooms, na.rm = TRUE),
            median(cleaned$bedrooms, na.rm=TRUE)
))
knitr::kable(table)

cleaned$bathrooms <- as.numeric(cleaned$bathrooms)


table <- data.frame(
  Statistic = c("Mean Bedrooms", "Max Bathrooms", "Min Bathrooms", "Median Bedrooms"),
  Value = c(round(mean(cleaned$bathrooms, na.rm=TRUE)),
            max(cleaned$bathrooms, na.rm = TRUE),
            min(cleaned$bathrooms, na.rm = TRUE),
            median(cleaned$bathrooms, na.rm=TRUE)
            
))
knitr::kable(table)

table <- data.frame(
  Statistic = c("Mean Population", "Max Population", "Min Population", "Median Population"),
  Value = c(round(mean(cleaned$population, na.rm=TRUE)),
            max(cleaned$population, na.rm = TRUE),
            min(cleaned$population, na.rm = TRUE),
            median(cleaned$population, na.rm=TRUE)
            
))
knitr::kable(table)



table <- data.frame(
  Statistic = c("Mean Density", "Max Density", "Min Density", "Median Density"),
  Value = c(round(mean(cleaned$density, na.rm=TRUE)),
            max(cleaned$density, na.rm = TRUE),
            min(cleaned$density, na.rm = TRUE),
            median(cleaned$density, na.rm=TRUE)
            
))
knitr::kable(table)

table <- data.frame(
  Statistic = c("Mean Density", "Max Density", "Min Density", "Median Density"),
  Value = c(round(mean(cleaned$density, na.rm=TRUE)),
            max(cleaned$density, na.rm = TRUE),
            min(cleaned$density, na.rm = TRUE),
            median(cleaned$density, na.rm=TRUE)
            
))
knitr::kable(table)

table <- data.frame(
  Statistic = c("Proportion with Photos", "Proportion with fees", "Proportion that allow pets"),
  Value = c(round(sum(cleaned$has_photo)/nrow(cleaned), 3),
            round(sum(cleaned$fee)/nrow(cleaned), 3),
            round(sum(cleaned$pets_allowed)/nrow(cleaned), 3)
))
knitr::kable(table)
```



# Data Analysis - Model Building

## Forward Stepwise Search

### First Iteration

For the first iteration of our stepwise search, we start off with a linear model that only consists of an intercept, $\beta_0$.

$$
Y = \beta_0
$$

After fitting the basic model with every predictor, we find that the Square feet variable results in the lowest P value of the model. We created an R function to
run forward stepwise search that inputs the potential variables to be included and
the variables already in the model.

```{r, echo=FALSE}

regression <- function(regressors, add_col = NULL) {
  low_pval <- 10
  best_var <- NULL
  adj_r2 <- 0
  best_var_sum <- NULL
  high_t_val <- 0
  AIC <- NULL
  AICc <- NULL
  BIC <- NULL
  # Iterate through the regressors
  for (i in regressors) {
    # Dynamically create the formula
    if (is.null(add_col) || length(add_col) == 0) {
      formula <- reformulate(i, response = "price")
    } else {
      formula <- reformulate(c(add_col, i), response = "price")
    }
    # Fit the linear model
    model <- invisible(lm(formula, data = cleaned))
    sum <- summary(model)
    # Extract the p-value for the slope (the last row of coefficients)
    # Ensure the slope term exists
    if (nrow(sum$coefficients) > 1) {
      pvalue <- sum$coefficients[nrow(sum$coefficients), "Pr(>|t|)"]
      tvalue <- abs(sum$coefficients[nrow(sum$coefficients), "t value"])
      # Update the lowest p-value and corresponding variable
      if (tvalue > high_t_val) {
        low_pval <- pvalue
        best_var <- i
        adj_r2 <- sum$adj.r.squared
        best_var_sum <- sum
        high_t_val <- tvalue
        AIC <- extractAIC(model, k=2)[2]
        npar <- length(sum$coefficients) + 1;
        n <- length(sum$residuals)
        AICc <- AIC + 2*npar*(npar + 1) / (n - npar - 1)
        BIC <- extractAIC(model, k = log(n))[2]
  residuals <- residuals(model)
  leverage <- hatvalues(model)
  press_statistic <- sum((residuals / (1 - leverage))^2)
      }
    }
  }
  # Return the variable with the lowest p-value
  return(c(best_var, low_pval, round(adj_r2, 3), round(AIC), round(AICc), round(BIC), round(press_statistic)))
}
regressor_list <- c("bedrooms", "bathrooms", "fee", "has_photo",
                    "pets_allowed", "square_feet",
                    "population", "density")
new <- regression(regressor_list)
table <- data.frame(
  Statistic = c("Predictor", "P-Value", "Adjusted R Squared", "AIC", "AICc", "BIC", "PRESS"), Values = new)
knitr::kable(table)
```

## Forward Stepwise Search {auto-animate="true"}

### Second Iteration
For the second iteration of our stepwise search, we use the linear model from the previous iteration, being the model with an intercept $\beta_0$ and a single predictor square feet, denoted as $X_1$.


$$
Y = \beta_0 + X_1\beta_1
$$

After fitting the model with every predictor, we find that the Density variable results in the lowest P value of the model.


## Forward Stepwise Search

### Second Iteration

The model improved when including density, while $AIC, AICc, BIC, PRESS$ got smaller.



$Model:$

$$
Y = \beta_0 + X_1\beta_1 + X_2\beta_2
$$

After fitting the model with every predictor, we find that the Population variable results in the lowest P value of the model.

## Forward Stepwise Search

### Third Iteration


## Forward Stepwise Search

### Completed


Hence, we have found our linear model, with the predictor variables being Square feet ($X_1$), and denstiy ($X_2$).

$$
Y=\beta_0 + X_1\beta_1 + X_2\beta_2
$$

$32\%$ of the variation in price explained by model

```{r, echo=FALSE}
cleaned$price1 <- log(cleaned$price)
model <- lm(price ~ square_feet + density, data=cleaned)
summary_model <- summary(model)
table <- data.frame(
  Statistic = c("Intercept", "Square Feet", "Density"),
  Values = c(round(summary_model$coefficients[1,1], 4),round(summary_model$coefficients[2,1], 4),round(summary_model$coefficients[3,1], 4)),
  SE = c(round(summary_model$coefficients[1,2],4),round(summary_model$coefficients[2,2], 4),round(summary_model$coefficients[3,2],4)),
  P_Value = c(summary_model$coefficients[1,4],summary_model$coefficients[2,4],summary_model$coefficients[3,4]),
  R_Squared = c(round(summary_model$r.squared,4), "", "")
)
  knitr::kable(table, caption = "Summary of Model")
```


# Analysis of Residuals - Model Improvement

## Residuals

### Residuals vs. Fitted Values

```{r, echo=FALSE}
model <- lm(price ~ square_feet + density, data=cleaned)
plot(model, which = 1)
```

We can see slight heteroskedasticity in this plot with a slight downward trend. 
As the fitted values become greater the residuals are greater indicating some model inaccuracy in high ranges. 

## Residuals

### Quantile-Quantile

```{r}
plot(model, which = 2)
```

Relatively normal, room for improvement

## Residuals

### Scale-Location

```{r}
plot(model, which = 3)
```

The Scale Location plot is not ideal, as the red line should be horizontal. The means homoscedasticity is violated, but this is likely to have higher variation in high-fitted values. As prices become more expensive, there are factors we can not account for, especially with luxury apartments.

## Residuals

### Residuals vs. Leverage

```{r}
plot(model, which = 5)
```

The dotted lines represent Cook's distance, highlighting several points that surpass its threshold. These points indicate high-leverage observations, which warrant further analysis to determine if they are outliers and whether they accurately reflect the relationship in question.

## Adjusted Model

### Outliers and Data Transformation

Address non-normality through Box-Cox transformation

```{r}
boxCox(model)
```

-   Optimal $\lambda$ close to 0

$$
y(\lambda) =
\begin{cases}
\frac{y^\lambda - 1}{\lambda}, & \text{if } \lambda \neq 0 \\[10pt]
\ln(y), & \text{if } \lambda = 0
\end{cases}
$$

## Adjusted Model

### Summary

Our adjusted model is: $\text{ln}(Y)=\beta_0+X_1\beta_1+X_2\beta_2$

```{r}
cleaned_new <- cleaned[-c(6754, 20556, 18779, 29745), ]
cleaned_new1 <- cleaned_new[-15668, ]
model_new <- lm(log(price) ~ square_feet + density, data=cleaned_new1)
summary_model <- summary(model_new)
table <- data.frame(
  Statistic = c("Intercept", "Square Feet", "Density"),
  Values = c(round(summary_model$coefficients[1,1], 4),round(summary_model$coefficients[2,1], 4),round(summary_model$coefficients[3,1], 4)),
  SE = c(round(summary_model$coefficients[1,2],4),round(summary_model$coefficients[2,2], 4),round(summary_model$coefficients[3,2],4)),
  P_Value = c(summary_model$coefficients[1,4],summary_model$coefficients[2,4],summary_model$coefficients[3,4]),
  R_Squared = c(round(summary_model$r.squared,4), "", "")
)
  knitr::kable(table, caption = "Summary of Model")
```


## Adjusted Model Residuals

### Residuals vs. Fitted Values

**Previous**

```{r fig.height=8, fig.width=10}
plot(model, which = 1)
```

**Adjusted**

```{r fig.height=8, fig.width=10}
plot(model_new, which = 1)
```

Normallity improved slightly

## Adjusted Model Residuals

### Quantile-Quantile

**Previous**

```{r fig.height=8, fig.width=10}
plot(model, which = 2)
```
**Adjusted**

```{r fig.height=8, fig.width=10}
plot(model_new, which = 2)
```

Significant Improvment 


## Adjusted Model Residuals

### Scale-Location


**Previous**

```{r fig.height=8, fig.width=10}
plot(model, which = 3)
```

**Adjusted**

```{r fig.height=8, fig.width=10}
plot(model_new, which = 3)
```

Slight homoscedasticity

## Adjusted Model Residuals

### Residuals vs. Leverage

**Previous**

```{r fig.height=8, fig.width=10}
plot(model, which = 5)
```

**Adjusted**

```{r fig.height=8, fig.width=10}
plot(model_new, which = 5)
```

Less high leverage points/outliers

## Confidence Interval

### Real Apartment Listing

The confidence interval generated by the model:

```{r}
calculated_density <- cities %>% filter(city == "houston", state_id == "TX") %>% select(density)
predictions <- predict(model_new, data.frame(square_feet = c(1200), density = c(2*calculated_density)), interval = "confidence", level = 0.95)
knitr::kable(exp(predictions))
```


-   Density metric was taken from the dataset
-   Scaled to account for higher density


Good Prediction

## Summary


-   Explored the data and found 8 usable regressors 5 of which were continuous and 3 of which were categorical
-   We used Forward Step wise Search to build our model and found 2 regressors for our final model, square_feet and density
-   Adjusted our model to take the log of price which improved $R^2$

------------------------------------------------------------------------

Limitations


-   Since Forward Step Wise Search is a greedy algorithm so it makes the best choice at each step and does not guarentee the most optimal solution
-   In the future we would like a data set with more regressors, our group hypothesizes that a regressor that represents the apartments luxuriousness would have a significant impact
    -   Could also use interaction terms to account for nonlinear effects



##Appendix

#Histogram

```{r fig.width=8, fig.height=6 }
data <- read.csv2("apartments.csv")
data$price <- as.numeric(data$price)
```


## Function to determine which variable has the lowest P-Value

```{r}
cleaned <- data %>%
              filter(currency == "USD", price_type == "Monthly", nchar(state) == 2, bathrooms != "null", !bedrooms %in% c("null", "USD", "") ) %>%
              mutate(pets_allowed = ifelse(pets_allowed %in% c("Cats", "Dogs", "Cats, Dogs", "Cats, Dogs, None"), 1, 0)) %>%
              mutate(has_photo = ifelse(has_photo %in% c("Thumbnail", "Yes"), 1, 0)) %>%
              mutate(fee = ifelse(fee == "Yes", 1, 0))
cities <- read.csv("uscities.csv")
cleaned <- cleaned %>%
  mutate(city = tolower(cityname), state = tolower(state))
cities <- cities %>%
  mutate(city = tolower(city), state = tolower(state_id))
cleaned <- cleaned %>%
  mutate(city = trimws(city), state = trimws(state))
cities <- cities %>%
  mutate(city = trimws(city), state = trimws(state))
data <- cleaned %>%
  left_join(cities %>% select(city, state, population, density),
            by = c("city", "state"))
#can do either median or mean.
pop_mean <- (mean(cities$population, na.rm=TRUE))
density_med <- mean(cities$density, na.rm=TRUE)
cleaned <- mutate(data, population = ifelse(is.na(population), pop_mean, population), density = ifelse(is.na(density), density_med, density))
Y <- cleaned$price
cleaned$bathrooms <- as.numeric(cleaned$bathrooms)
cleaned$bedrooms <- as.numeric(cleaned$bedrooms)
cleaned$price <- as.numeric(cleaned$price)
cleaned$density <- as.numeric(cleaned$density)
cleaned$population <- as.numeric(cleaned$population)
cleaned$square_feet <- as.numeric(cleaned$square_feet)
regression <- function(regressors, add_col = NULL) {
  low_pval <- 10
  best_var <- NULL
  adj_r2 <- 0
  best_var_sum <- NULL
  high_t_val <- 0
  AIC <- NULL
  AICc <- NULL
  BIC <- NULL
  # Iterate through the regressors
  for (i in regressors) {
    # Dynamically create the formula
    if (is.null(add_col) || length(add_col) == 0) {
      formula <- reformulate(i, response = "price")
    } else {
      formula <- reformulate(c(add_col, i), response = "price")
    }
    # Fit the linear model
    model <- invisible(lm(formula, data = cleaned))
    sum <- summary(model)
    # Extract the p-value for the slope (the last row of coefficients)
    # Ensure the slope term exists
    if (nrow(sum$coefficients) > 1) {
      pvalue <- sum$coefficients[nrow(sum$coefficients), "Pr(>|t|)"]
      tvalue <- abs(sum$coefficients[nrow(sum$coefficients), "t value"])
      # Update the lowest p-value and corresponding variable
      if (tvalue > high_t_val) {
        low_pval <- pvalue
        best_var <- i
        adj_r2 <- sum$adj.r.squared
        best_var_sum <- sum
        high_t_val <- tvalue
        AIC <- extractAIC(model, k=2)[2]
        npar <- length(sum$coefficients) + 1;
        n <- length(sum$residuals)
        AICc <- AIC + 2*npar*(npar + 1) / (n - npar - 1)
        BIC <- extractAIC(model, k = log(n))[2]
  residuals <- residuals(model)
  leverage <- hatvalues(model)
  press_statistic <- sum((residuals / (1 - leverage))^2)
      }
    }
  }
  # Return the variable with the lowest p-value
  return(c(best_var, low_pval, adj_r2, AIC, AICc, BIC, press_statistic))
}
```






